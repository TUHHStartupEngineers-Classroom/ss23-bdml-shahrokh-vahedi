{
  "hash": "028c07f3ad3a33d3959da06bd9d6956a",
  "result": {
    "markdown": "---\ntitle: \"04 Automated Machine Learning with H2O (II)\"\ndate: \"2023-06-10\"\noutput:\n  html_document:\n    toc: yes\n    toc_float: yes\n    df_print: paged\n    collapsed: no\n    number_sections: yes\n    toc_depth: 3\n  pdf_document:\n    toc: yes\n    toc_depth: '3'\n---\n\n\n\n\n## Load the training & test dataset\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-1_e72c6a0b51937526b04ef5abcbeff50d'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(rsample)\n\ndataset <- read_csv(\"data04/product_backorders.csv\") %>% \n  mutate(product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()) %>% select(-c(went_on_backorder))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nglimpse(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 19,053\n#> Columns: 23\n#> $ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453~\n#> $ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,~\n#> $ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2~\n#> $ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0~\n#> $ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4~\n#> $ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, ~\n#> $ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, ~\n#> $ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, ~\n#> $ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3~\n#> $ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4~\n#> $ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0~\n#> $ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0~\n#> $ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n#> $ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00~\n#> $ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95~\n#> $ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, ~\n#> $ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No~\n#> $ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye~\n#> $ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ product_backorder <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n```\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(dataset, prop = 0.85)\ntrain_data<- training(split_obj)\ntest_data<- testing(split_obj)\n```\n:::\n\n\n## Specifiy the response and predictor variables\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-2_e5a18dda196bebcd6d04b99362dee04a'}\n\n```{.r .cell-code}\nrecipe_obj <- recipe(product_backorder ~., data = train_data) %>% \n    step_zv(all_predictors()) %>% \n    step_dummy(all_nominal(),-all_outcomes()) %>%\n    prep()\n\nsummary(recipe_obj)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"type\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"role\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"sku\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"national_inv\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"lead_time\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"in_transit_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_1_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"min_bank\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"pieces_past_due\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_6_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_12_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"local_bo_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"product_backorder\",\"2\":\"<chr [2]>\",\"3\":\"outcome\",\"4\":\"original\"},{\"1\":\"potential_issue_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"deck_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"oe_constraint_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"ppap_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"stop_auto_buy_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"rev_stop_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nglimpse(bake(recipe_obj,new_data = NULL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 16,195\n#> Columns: 23\n#> $ sku                 <dbl> 2003094, 1446382, 1181601, 2041493, 2898957, 19291~\n#> $ national_inv        <dbl> 0, 2, 616, 10, 97, 33, 5, 8, 11, 508, 2, 6, 2, 3, ~\n#> $ lead_time           <dbl> 4, 2, 2, 8, 2, 8, 2, 2, 8, 8, 9, 8, 12, 4, 14, 8, ~\n#> $ in_transit_qty      <dbl> 0, 0, 0, 0, 27, 0, 0, 0, 0, 123, 0, 0, 0, 3, 0, 9,~\n#> $ forecast_3_month    <dbl> 11, 0, 0, 0, 273, 0, 0, 0, 0, 1734, 0, 2, 0, 0, 0,~\n#> $ forecast_6_month    <dbl> 11, 0, 0, 0, 525, 0, 0, 0, 3, 2690, 0, 8, 0, 2, 0,~\n#> $ forecast_9_month    <dbl> 11, 0, 0, 0, 735, 13, 0, 1, 12, 2920, 0, 16, 0, 3,~\n#> $ sales_1_month       <dbl> 0, 0, 1, 0, 73, 5, 0, 0, 5, 181, 0, 0, 0, 0, 0, 48~\n#> $ sales_3_month       <dbl> 0, 0, 2, 0, 224, 22, 0, 1, 9, 572, 0, 4, 0, 2, 0, ~\n#> $ sales_6_month       <dbl> 0, 0, 5, 0, 450, 38, 0, 2, 20, 1342, 0, 11, 0, 6, ~\n#> $ sales_9_month       <dbl> 0, 0, 6, 0, 682, 67, 0, 2, 24, 3138, 0, 13, 0, 7, ~\n#> $ min_bank            <dbl> 1, 0, 0, 1, 53, 5, 0, 0, 0, 209, 0, 0, 0, 0, 0, 96~\n#> $ pieces_past_due     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ perf_6_month_avg    <dbl> 0.24, 0.98, 0.99, 0.99, 0.93, 0.99, 0.99, 0.77, 0.~\n#> $ perf_12_month_avg   <dbl> 0.14, 0.95, 0.97, 0.99, 0.89, 0.99, 0.99, 0.49, 0.~\n#> $ local_bo_qty        <dbl> 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n#> $ product_backorder   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ potential_issue_Yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ deck_risk_Yes       <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ oe_constraint_Yes   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ ppap_risk_Yes       <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,~\n#> $ stop_auto_buy_Yes   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n#> $ rev_stop_Yes        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n```\n:::\n:::\n\n\n## run AutoML specifying the stopping criterion\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-3_2eb44ef7d5cda0372a5acd6ef06fc6e0'}\n\n```{.r .cell-code}\nlibrary(h2o)\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         1 hours 29 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 16 days \n#>     H2O cluster name:           H2O_started_from_R_Shahrokh_dje900 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   0.79 GB \n#>     H2O cluster total cores:    4 \n#>     H2O cluster allowed cores:  4 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21 ucrt)\n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_data), ratios = c(0.85), seed = 52)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"product_backorder\"\nx <- setdiff(names(train_h2o), y)\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 140,\n  nfolds            = 5,\n  stopping_metric = \"mae\", stopping_rounds = 3,\n                        stopping_tolerance = 1e-3\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n#> 15:03:33.692: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 15:03:33.694: Stopping tolerance set by the user is < 70% of the recommended default of 0.008512565307587486, so models may take a long time to converge or may not converge at all.\n#> 15:03:33.713: AutoML: XGBoost is not available; skipping it.\n#> 15:03:33.784: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:03:33.784: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===                                                                   |   4%\n#> 15:03:37.919: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:03:37.919: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |=============================                                         |  41%\n#> 15:04:32.205: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:04:32.205: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  46%\n#> 15:04:37.800: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:04:37.801: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |======================================                                |  54%\n#> 15:04:49.923: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:04:49.924: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |=============================================                         |  64%\n#> 15:05:02.635: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:02.636: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n#> 15:05:15.577: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:15.578: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  83%\n#> 15:05:29.291: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:29.291: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===========================================================           |  85%\n#> 15:05:33.50: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:33.50: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  89%\n#> 15:05:38.474: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:38.474: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |================================================================      |  92%\n#> 15:05:41.704: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:41.705: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==================================================================    |  94%\n#> 15:05:44.940: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:44.940: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |====================================================================  |  97%\n#> 15:05:49.271: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:49.271: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n#> 15:05:53.444: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 15:05:53.444: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n```\n:::\n:::\n\n\n## View the leaderboard\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-4_0ba2f15d38d2c07e348ab1cf3726ae7c'}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                  model_id      rmse        mse\n#> 1 StackedEnsemble_BestOfFamily_2_AutoML_7_20230613_150333 0.2238527 0.05011002\n#> 2    StackedEnsemble_AllModels_2_AutoML_7_20230613_150333 0.2239285 0.05014395\n#> 3    StackedEnsemble_AllModels_1_AutoML_7_20230613_150333 0.2240410 0.05019439\n#> 4 StackedEnsemble_BestOfFamily_3_AutoML_7_20230613_150333 0.2240663 0.05020570\n#> 5                          GBM_4_AutoML_7_20230613_150333 0.2280299 0.05199763\n#> 6                          GBM_3_AutoML_7_20230613_150333 0.2292833 0.05257081\n#>         mae     rmsle mean_residual_deviance\n#> 1 0.1197909 0.1563357             0.05011002\n#> 2 0.1212188 0.1570722             0.05014395\n#> 3 0.1217558 0.1572235             0.05019439\n#> 4 0.1188522 0.1561823             0.05020570\n#> 5 0.1229130 0.1580747             0.05199763\n#> 6 0.1227182 0.1587060             0.05257081\n#> \n#> [14 rows x 6 columns]\n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leader\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Model Details:\n#> ==============\n#> \n#> H2ORegressionModel: stackedensemble\n#> Model ID:  StackedEnsemble_BestOfFamily_2_AutoML_7_20230613_150333 \n#> Model Summary for Stacked Ensemble: \n#>                                     key            value\n#> 1                     Stacking strategy cross_validation\n#> 2  Number of base models (used / total)              2/3\n#> 3      # GBM base models (used / total)              1/1\n#> 4      # DRF base models (used / total)              1/1\n#> 5      # GLM base models (used / total)              0/1\n#> 6                 Metalearner algorithm              GLM\n#> 7    Metalearner fold assignment scheme           Random\n#> 8                    Metalearner nfolds                5\n#> 9               Metalearner fold_column               NA\n#> 10   Custom metalearner hyperparameters             None\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on training data. **\n#> \n#> MSE:  0.03118179\n#> RMSE:  0.1765837\n#> MAE:  0.09491372\n#> RMSLE:  0.1240345\n#> Mean Residual Deviance :  0.03118179\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.05113511\n#> RMSE:  0.2261307\n#> MAE:  0.1187695\n#> RMSLE:  0.1597094\n#> Mean Residual Deviance :  0.05113511\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05585049\n#> RMSE:  0.2363271\n#> MAE:  0.1281826\n#> RMSLE:  0.1660027\n#> Mean Residual Deviance :  0.05585049\n#> \n#> \n#> Cross-Validation Metrics Summary: \n#>                              mean       sd cv_1_valid cv_2_valid cv_3_valid\n#> mae                      0.128143 0.003582   0.128664   0.125750   0.133788\n#> mean_residual_deviance   0.055844 0.003179   0.055055   0.052784   0.061032\n#> mse                      0.055844 0.003179   0.055055   0.052784   0.061032\n#> null_deviance          294.516000 6.591096 298.259860 298.508330 289.537570\n#> r2                       0.476549 0.028720   0.488863   0.507356   0.432752\n#> residual_deviance      154.013980 6.272614 152.447780 147.057460 164.236470\n#> rmse                     0.236238 0.006655   0.234638   0.229749   0.247046\n#> rmsle                    0.165742 0.003994   0.165399   0.161340   0.172139\n#>                        cv_4_valid cv_5_valid\n#> mae                      0.128037   0.124477\n#> mean_residual_deviance   0.056324   0.054025\n#> mse                      0.056324   0.054025\n#> null_deviance          300.727480 285.546720\n#> r2                       0.488725   0.465051\n#> residual_deviance      153.708470 152.619700\n#> rmse                     0.237327   0.232432\n#> rmsle                    0.165924   0.163908\n```\n:::\n\n```{.r .cell-code}\n?h2o.deeplearning\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> starting httpd help server ... done\n```\n:::\n\n```{.r .cell-code}\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n    model_name <- h2o_leaderboard %>%\n        as.tibble() %>%\n        slice_(n) %>%\n        pull(model_id)\n    if (verbose) message(model_name)\n    return(model_name)\n}\n```\n:::\n\n\n## Predicting using Leader Model\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-5_457f423cb9a3da3176771272aef2e95b'}\n\n```{.r .cell-code}\nbest_model <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `slice_()` was deprecated in dplyr 0.7.0.\n#> i Please use `slice()` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> i Please use `as_tibble()` instead.\n#> i The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> StackedEnsemble_AllModels_1_AutoML_2_20230612_12304\n```\n:::\n\n```{.r .cell-code}\npredictions <- h2o.predict(best_model, newdata = as.h2o(test_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntypeof(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"environment\"\n```\n:::\n\n```{.r .cell-code}\npredictions_tbl <- predictions %>% as_tibble()\n\nglimpse(predictions_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 2,858\n#> Columns: 1\n#> $ predict <dbl> 0.45918184, 0.69144190, 0.08459433, 0.48058109, 0.19629379, 0.~\n```\n:::\n:::\n\n\n## Save the leader model\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-6_7d35b2a91c067cde2d8e24bc32e0b77f'}\n\n```{.r .cell-code}\nbest_model %>% h2o.saveModel(path = \"data04/model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"C:\\\\Users\\\\Shahrokh\\\\Documents\\\\GitHub\\\\ss23-bdml-shahrokh-vahedi\\\\content\\\\01_journal\\\\data04\\\\model\\\\StackedEnsemble_AllModels_1_AutoML_1_20230612_05038\"\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}