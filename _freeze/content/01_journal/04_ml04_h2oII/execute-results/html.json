{
  "hash": "f8f561a0b57679fa8ee9032d3cdd5280",
  "result": {
    "markdown": "---\ntitle: \"04 Automated Machine Learning with H2O (II)\"\ndate: \"2023-06-13\"\noutput:\n  html_document:\n    toc: yes\n    toc_float: yes\n    df_print: paged\n    collapsed: no\n    number_sections: yes\n    toc_depth: 3\n  pdf_document:\n    toc: yes\n    toc_depth: '3'\n---\n\n\n\n\n## Load the training & test dataset\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-1_e72c6a0b51937526b04ef5abcbeff50d'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(recipes)\nlibrary(rsample)\n\ndataset <- read_csv(\"data04/product_backorders.csv\") %>% \n  mutate(product_backorder = went_on_backorder %>% str_to_lower() %>% str_detect(\"yes\") %>% as.numeric()) %>% select(-c(went_on_backorder))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 19053 Columns: 23\n#> -- Column specification --------------------------------------------------------\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> i Use `spec()` to retrieve the full column specification for this data.\n#> i Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nglimpse(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 19,053\n#> Columns: 23\n#> $ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453~\n#> $ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,~\n#> $ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2~\n#> $ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0~\n#> $ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4~\n#> $ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, ~\n#> $ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, ~\n#> $ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, ~\n#> $ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3~\n#> $ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4~\n#> $ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0~\n#> $ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0~\n#> $ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n#> $ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00~\n#> $ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95~\n#> $ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, ~\n#> $ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No~\n#> $ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye~\n#> $ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"~\n#> $ product_backorder <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1~\n```\n:::\n\n```{.r .cell-code}\nsplit_obj<- initial_split(dataset, prop = 0.85)\ntrain_data<- training(split_obj)\ntest_data<- testing(split_obj)\n```\n:::\n\n\n## Specifiy the response and predictor variables\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-2_e5a18dda196bebcd6d04b99362dee04a'}\n\n```{.r .cell-code}\nrecipe_obj <- recipe(product_backorder ~., data = train_data) %>% \n    step_zv(all_predictors()) %>% \n    step_dummy(all_nominal(),-all_outcomes()) %>%\n    prep()\n\nsummary(recipe_obj)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"variable\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"type\"],\"name\":[2],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"role\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"sku\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"national_inv\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"lead_time\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"in_transit_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"forecast_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_1_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_3_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_6_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"sales_9_month\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"min_bank\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"pieces_past_due\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_6_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"perf_12_month_avg\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"local_bo_qty\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"original\"},{\"1\":\"product_backorder\",\"2\":\"<chr [2]>\",\"3\":\"outcome\",\"4\":\"original\"},{\"1\":\"potential_issue_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"deck_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"oe_constraint_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"ppap_risk_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"stop_auto_buy_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"},{\"1\":\"rev_stop_Yes\",\"2\":\"<chr [2]>\",\"3\":\"predictor\",\"4\":\"derived\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nglimpse(bake(recipe_obj,new_data = NULL))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 16,195\n#> Columns: 23\n#> $ sku                 <dbl> 1838853, 1371461, 3104494, 1625544, 1610415, 14638~\n#> $ national_inv        <dbl> 20, 201, 14, 11, 0, 9, 21, 12, 11, 66, 24, 128, 12~\n#> $ lead_time           <dbl> 12, 2, 8, 2, NA, 2, 8, 12, 2, 4, 8, 8, 12, 2, 2, N~\n#> $ in_transit_qty      <dbl> 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ forecast_3_month    <dbl> 0, 0, 12, 0, 50, 0, 0, 8, 10, 0, 19, 0, 0, 0, 12, ~\n#> $ forecast_6_month    <dbl> 0, 0, 24, 0, 50, 0, 0, 8, 10, 0, 42, 0, 0, 0, 18, ~\n#> $ forecast_9_month    <dbl> 0, 0, 36, 0, 50, 0, 0, 16, 10, 0, 58, 0, 0, 0, 24,~\n#> $ sales_1_month       <dbl> 0, 8, 3, 1, 0, 1, 0, 3, 8, 1, 2, 1, 0, 0, 1, 0, 2,~\n#> $ sales_3_month       <dbl> 0, 19, 8, 2, 0, 2, 1, 10, 11, 1, 12, 2, 0, 0, 4, 4~\n#> $ sales_6_month       <dbl> 0, 41, 22, 4, 0, 5, 3, 23, 22, 1, 37, 3, 5, 0, 7, ~\n#> $ sales_9_month       <dbl> 0, 60, 37, 6, 0, 8, 9, 38, 33, 5, 66, 3, 6, 0, 15,~\n#> $ min_bank            <dbl> 1, 7, 2, 0, 0, 0, 0, 0, 1, 0, 9, 0, 1, 0, 1, 1, 1,~\n#> $ pieces_past_due     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0~\n#> $ perf_6_month_avg    <dbl> 0.58, 0.84, 0.99, 0.38, -99.00, 0.87, 0.80, 0.83, ~\n#> $ perf_12_month_avg   <dbl> 0.58, 0.82, 0.98, 0.40, -99.00, 0.75, 0.82, 0.90, ~\n#> $ local_bo_qty        <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ product_backorder   <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ potential_issue_Yes <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ deck_risk_Yes       <dbl> 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,~\n#> $ oe_constraint_Yes   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n#> $ ppap_risk_Yes       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,~\n#> $ stop_auto_buy_Yes   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~\n#> $ rev_stop_Yes        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~\n```\n:::\n:::\n\n\n## run AutoML specifying the stopping criterion\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-3_2eb44ef7d5cda0372a5acd6ef06fc6e0'}\n\n```{.r .cell-code}\nlibrary(h2o)\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> H2O is not running yet, starting it now...\n#> \n#> Note:  In case of errors look at the following log files:\n#>     C:\\Users\\Shahrokh\\AppData\\Local\\Temp\\Rtmpec1Ssy\\file15543c371190/h2o_Shahrokh_started_from_r.out\n#>     C:\\Users\\Shahrokh\\AppData\\Local\\Temp\\Rtmpec1Ssy\\file15544fce2426/h2o_Shahrokh_started_from_r.err\n#> \n#> \n#> Starting H2O JVM and connecting: . Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         3 seconds 310 milliseconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.4 \n#>     H2O cluster version age:    1 month and 16 days \n#>     H2O cluster name:           H2O_started_from_R_Shahrokh_nhe595 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   0.99 GB \n#>     H2O cluster total cores:    4 \n#>     H2O cluster allowed cores:  4 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.0 (2023-04-21 ucrt)\n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_data), ratios = c(0.85), seed = 52)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"product_backorder\"\nx <- setdiff(names(train_h2o), y)\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 140,\n  nfolds            = 5,\n  stopping_metric = \"mae\", stopping_rounds = 3,\n                        stopping_tolerance = 1e-3\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n#> 11:07:52.551: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 11:07:52.551: Stopping tolerance set by the user is < 70% of the recommended default of 0.008512565307587486, so models may take a long time to converge or may not converge at all.\n#> 11:07:52.597: AutoML: XGBoost is not available; skipping it.\n#> 11:07:52.850: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:07:52.850: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==                                                                    |   3%\n#> 11:07:55.838: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:07:55.838: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n#> 11:08:20.50: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:20.50: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===============                                                       |  22%\n#> 11:08:23.144: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:23.144: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  29%\n#> 11:08:33.117: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:33.117: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  35%\n#> 11:08:41.279: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:41.279: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n#> 11:08:49.109: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:49.110: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n#> 11:08:57.91: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:57.91: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=================================                                     |  48%\n#> 11:08:59.98: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:08:59.98: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===================================                                   |  49%\n#> 11:09:01.207: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:09:01.207: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  55%\n#> 11:09:09.861: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:09:09.861: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n#> 11:09:16.41: _train param, Dropping bad and constant columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:09:16.41: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |=============================================                         |  64%\n#> 11:09:21.901: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:09:21.901: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |==============================================                        |  65%\n#> 11:09:23.698: _train param, Dropping unused columns: [potential_issue, ppap_risk, rev_stop, stop_auto_buy, deck_risk, oe_constraint]\n#> 11:09:23.698: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n\n## View the leaderboard\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-4_0ba2f15d38d2c07e348ab1cf3726ae7c'}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                  model_id      rmse        mse\n#> 1 StackedEnsemble_BestOfFamily_3_AutoML_1_20230614_110752 0.2260784 0.05111146\n#> 2    StackedEnsemble_AllModels_2_AutoML_1_20230614_110752 0.2260897 0.05111653\n#> 3    StackedEnsemble_AllModels_1_AutoML_1_20230614_110752 0.2272044 0.05162185\n#> 4 StackedEnsemble_BestOfFamily_2_AutoML_1_20230614_110752 0.2273878 0.05170522\n#> 5                          GBM_4_AutoML_1_20230614_110752 0.2291999 0.05253261\n#> 6 StackedEnsemble_BestOfFamily_1_AutoML_1_20230614_110752 0.2330037 0.05429072\n#>         mae     rmsle mean_residual_deviance\n#> 1 0.1185425 0.1592269             0.05111146\n#> 2 0.1189984 0.1593067             0.05111653\n#> 3 0.1191355 0.1597273             0.05162185\n#> 4 0.1182341 0.1596554             0.05170522\n#> 5 0.1199089 0.1601677             0.05253261\n#> 6 0.1324803 0.1653251             0.05429072\n#> \n#> [20 rows x 6 columns]\n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leader\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Model Details:\n#> ==============\n#> \n#> H2ORegressionModel: stackedensemble\n#> Model ID:  StackedEnsemble_BestOfFamily_3_AutoML_1_20230614_110752 \n#> Model Summary for Stacked Ensemble: \n#>                                          key            value\n#> 1                          Stacking strategy cross_validation\n#> 2       Number of base models (used / total)              3/5\n#> 3           # GBM base models (used / total)              1/1\n#> 4           # DRF base models (used / total)              2/2\n#> 5  # DeepLearning base models (used / total)              0/1\n#> 6           # GLM base models (used / total)              0/1\n#> 7                      Metalearner algorithm              GLM\n#> 8         Metalearner fold assignment scheme           Random\n#> 9                         Metalearner nfolds                5\n#> 10                   Metalearner fold_column               NA\n#> 11        Custom metalearner hyperparameters             None\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on training data. **\n#> \n#> MSE:  0.02146429\n#> RMSE:  0.146507\n#> MAE:  0.07564131\n#> RMSLE:  0.1041786\n#> Mean Residual Deviance :  0.02146429\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.04901898\n#> RMSE:  0.2214023\n#> MAE:  0.1132232\n#> RMSLE:  0.1551188\n#> Mean Residual Deviance :  0.04901898\n#> \n#> \n#> H2ORegressionMetrics: stackedensemble\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05079553\n#> RMSE:  0.2253786\n#> MAE:  0.1148825\n#> RMSLE:  0.1586652\n#> Mean Residual Deviance :  0.05079553\n#> \n#> \n#> Cross-Validation Metrics Summary: \n#>                              mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> mae                      0.114841  0.003039   0.117218   0.118837   0.111746\n#> mean_residual_deviance   0.050736  0.002342   0.052726   0.053384   0.050029\n#> mse                      0.050736  0.002342   0.052726   0.053384   0.050029\n#> null_deviance          286.679020 20.626400 292.309900 318.461980 275.582950\n#> r2                       0.510150  0.021777   0.499249   0.535458   0.495200\n#> residual_deviance      140.030330  6.727001 146.366400 147.500580 139.031620\n#> rmse                     0.225198  0.005206   0.229621   0.231050   0.223672\n#> rmsle                    0.158399  0.003175   0.161402   0.161320   0.157154\n#>                        cv_4_valid cv_5_valid\n#> mae                      0.112768   0.113637\n#> mean_residual_deviance   0.047601   0.049940\n#> mse                      0.047601   0.049940\n#> null_deviance          283.279600 263.760620\n#> r2                       0.531800   0.489043\n#> residual_deviance      132.615250 134.637830\n#> rmse                     0.218176   0.223472\n#> rmsle                    0.153792   0.158329\n```\n:::\n\n```{.r .cell-code}\n?h2o.deeplearning\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> starting httpd help server ... done\n```\n:::\n\n```{.r .cell-code}\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n    model_name <- h2o_leaderboard %>%\n        as.tibble() %>%\n        slice_(n) %>%\n        pull(model_id)\n    if (verbose) message(model_name)\n    return(model_name)\n}\n```\n:::\n\n\n## Predicting using Leader Model\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-5_457f423cb9a3da3176771272aef2e95b'}\n\n```{.r .cell-code}\nbest_model <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `slice_()` was deprecated in dplyr 0.7.0.\n#> i Please use `slice()` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Warning: `as.tibble()` was deprecated in tibble 2.0.0.\n#> i Please use `as_tibble()` instead.\n#> i The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> StackedEnsemble_BestOfFamily_3_AutoML_1_20230614_110752\n```\n:::\n\n```{.r .cell-code}\npredictions <- h2o.predict(best_model, newdata = as.h2o(test_data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntypeof(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"environment\"\n```\n:::\n\n```{.r .cell-code}\npredictions_tbl <- predictions %>% as_tibble()\n\nglimpse(predictions_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 2,858\n#> Columns: 1\n#> $ predict <dbl> 0.4612117, 0.1123560, 0.2041894, 0.3293324, 0.6088410, 0.21537~\n```\n:::\n:::\n\n\n## Save the leader model\n\n\n::: {.cell hash='04_ml04_h2oII_cache/html/unnamed-chunk-6_7d35b2a91c067cde2d8e24bc32e0b77f'}\n\n```{.r .cell-code}\nbest_model %>% h2o.saveModel(path = \"data04/model\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"C:\\\\Users\\\\Shahrokh\\\\Documents\\\\GitHub\\\\ss23-bdml-shahrokh-vahedi\\\\content\\\\01_journal\\\\data04\\\\model\\\\StackedEnsemble_BestOfFamily_3_AutoML_1_20230614_110752\"\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}